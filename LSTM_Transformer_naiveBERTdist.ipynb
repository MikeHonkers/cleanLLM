{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f02c652f8ae346ff928e1fb18d7973b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b26323541a274fefb7b6eb1afafe2a5b",
              "IPY_MODEL_d2e55061d9e648e587de1673170ab369",
              "IPY_MODEL_c9876a815d7347feb8f670657d59a8b9"
            ],
            "layout": "IPY_MODEL_e665c7f9ba7f4e4ab041ebe1f4aea6f4"
          }
        },
        "b26323541a274fefb7b6eb1afafe2a5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b0d96f52ceb4ead9ff3ed1cd03053de",
            "placeholder": "​",
            "style": "IPY_MODEL_524bd90cee3844bf812086cdab492a35",
            "value": "config.json: 100%"
          }
        },
        "d2e55061d9e648e587de1673170ab369": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_215f9dd5b8f7450181bfbd745436cdfa",
            "max": 919,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_21288920139741d3abac00a409aa8f24",
            "value": 919
          }
        },
        "c9876a815d7347feb8f670657d59a8b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21bcaf6b9906405185c958be3a62facb",
            "placeholder": "​",
            "style": "IPY_MODEL_ab7c1c4f3707408c92f5e1c1dda1bbd6",
            "value": " 919/919 [00:00&lt;00:00, 68.9kB/s]"
          }
        },
        "e665c7f9ba7f4e4ab041ebe1f4aea6f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b0d96f52ceb4ead9ff3ed1cd03053de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "524bd90cee3844bf812086cdab492a35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "215f9dd5b8f7450181bfbd745436cdfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21288920139741d3abac00a409aa8f24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "21bcaf6b9906405185c958be3a62facb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab7c1c4f3707408c92f5e1c1dda1bbd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ddd95eeff82b445f840a6d1cb7abe9b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ca7736ddf2c64b0e9dc3318968640190",
              "IPY_MODEL_55e3780da3b4416ca10753693ba75e72",
              "IPY_MODEL_da25f18fc0d1478cb7a8c827700dc2ef"
            ],
            "layout": "IPY_MODEL_6bba299848944ccb8250fc5cf861c4fb"
          }
        },
        "ca7736ddf2c64b0e9dc3318968640190": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82cfa43b197b499e95bf8cf793fd2d37",
            "placeholder": "​",
            "style": "IPY_MODEL_f0b3e11025a34fd382ba4912195b33e5",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "55e3780da3b4416ca10753693ba75e72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c720d770a6e4f90bb1275c645a98aa7",
            "max": 438030207,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_24bdfb8e6789453bbb4614ad75f630a8",
            "value": 438030207
          }
        },
        "da25f18fc0d1478cb7a8c827700dc2ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8687fc19733f444c84cbfcef3535ccfe",
            "placeholder": "​",
            "style": "IPY_MODEL_6944d6d92d304c6fa7458fb8df56f7cc",
            "value": " 438M/438M [00:01&lt;00:00, 274MB/s]"
          }
        },
        "6bba299848944ccb8250fc5cf861c4fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82cfa43b197b499e95bf8cf793fd2d37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0b3e11025a34fd382ba4912195b33e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c720d770a6e4f90bb1275c645a98aa7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24bdfb8e6789453bbb4614ad75f630a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8687fc19733f444c84cbfcef3535ccfe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6944d6d92d304c6fa7458fb8df56f7cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U datasets -q"
      ],
      "metadata": {
        "id": "ca9vPWZ6cjBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ALmkUTRI2q5J"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from dataclasses import dataclass\n",
        "import copy\n",
        "import wandb\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from datasets import load_dataset\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "bert_model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=4).to(device)"
      ],
      "metadata": {
        "id": "WQXjmFW37J3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(bert_model)\n",
        "print(sum(p.numel() for p in bert_model.parameters())) # 110M\n",
        "# 768 embedding\n",
        "# 12 слоёв, {Attention (768), Intermidiate + Output (768 -> 3072 -> 768)}\n",
        "# 768 -> 4 classifier"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-CnpTF0844i",
        "outputId": "5e182bad-e259-495c-cc8a-2ada50f6f41a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertForSequenceClassification(\n",
            "  (bert): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0-11): 12 x BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSdpaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): BertPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
            ")\n",
            "109485316\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(bert_model.bert.embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QregcoPbC0Kv",
        "outputId": "fbc3806f-d9fa-4ccf-d149-bc4b9a02a3f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertEmbeddings(\n",
            "  (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "  (position_embeddings): Embedding(512, 768)\n",
            "  (token_type_embeddings): Embedding(2, 768)\n",
            "  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class LSTMBERTConfig:\n",
        "    bert_hidden_size: int = 768\n",
        "    num_blocks: int = 6\n",
        "    num_heads: int = 12\n",
        "    intermediate_size: int = 1024\n",
        "    dropout: float = 0.1\n",
        "\n",
        "config = LSTMBERTConfig()"
      ],
      "metadata": {
        "id": "_BPRpdzG7wwL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMTransformerBlock(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=config.bert_hidden_size,\n",
        "            hidden_size=config.bert_hidden_size // 2,\n",
        "            num_layers=1,\n",
        "            batch_first=True,\n",
        "            bidirectional=True\n",
        "        )\n",
        "\n",
        "        self.mha = nn.MultiheadAttention(\n",
        "            embed_dim=config.bert_hidden_size,\n",
        "            num_heads=config.num_heads,\n",
        "            dropout=config.dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        self.ffn = nn.Sequential(\n",
        "            nn.Linear(config.bert_hidden_size, config.intermediate_size),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(config.intermediate_size, config.bert_hidden_size)\n",
        "        )\n",
        "\n",
        "        self.layernorm1 = nn.LayerNorm(config.bert_hidden_size, eps=1e-12)\n",
        "        self.layernorm2 = nn.LayerNorm(config.bert_hidden_size, eps=1e-12)\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "    def forward(self, x, attention_mask=None, return_attention=False):\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            attention_mask = ~attention_mask.bool()\n",
        "        else:\n",
        "            attention_mask = None\n",
        "\n",
        "        mha_out, attn_weights = self.mha(\n",
        "            query=x,\n",
        "            key=x,\n",
        "            value=x,\n",
        "            key_padding_mask=attention_mask,\n",
        "            need_weights=return_attention\n",
        "        )\n",
        "\n",
        "        combined = self.layernorm1(mha_out + lstm_out)\n",
        "        combined = self.dropout(combined)\n",
        "\n",
        "        ffn_out = self.ffn(combined)\n",
        "        output = self.layernorm2(ffn_out + combined)\n",
        "        output = self.dropout(output)\n",
        "\n",
        "        if return_attention:\n",
        "            return output, attn_weights\n",
        "        else:\n",
        "            return output\n",
        "\n",
        "class CleanBERT(nn.Module):\n",
        "    def __init__(self, embedding_layer, config, num_labels=4):\n",
        "        super().__init__()\n",
        "        self.embeddings = embedding_layer\n",
        "\n",
        "        self.blocks = nn.ModuleList([\n",
        "            LSTMTransformerBlock(config) for _ in range(config.num_blocks)\n",
        "        ])\n",
        "\n",
        "        self.pooler = nn.Sequential(\n",
        "            nn.Linear(config.bert_hidden_size, config.bert_hidden_size),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "        self.classifier = nn.Linear(config.bert_hidden_size, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None,\n",
        "                return_hidden_states=False, return_attentions=False):\n",
        "        x = self.embeddings(input_ids)\n",
        "\n",
        "        all_hidden_states = []\n",
        "        all_attentions = []\n",
        "\n",
        "        if return_hidden_states:\n",
        "            all_hidden_states.append(x)\n",
        "\n",
        "        for block in self.blocks:\n",
        "            if return_attentions:\n",
        "                x, attn = block(x, attention_mask=attention_mask, return_attention=True)\n",
        "                all_attentions.append(attn)\n",
        "            else:\n",
        "                x = block(x, attention_mask=attention_mask, return_attention=False)\n",
        "\n",
        "            if return_hidden_states:\n",
        "                all_hidden_states.append(x)\n",
        "\n",
        "        cls_output = x[:, 0]\n",
        "\n",
        "        pooled = self.pooler(cls_output)\n",
        "        pooled = self.dropout(pooled)\n",
        "        logits = self.classifier(pooled)\n",
        "\n",
        "        outputs = {\"logits\": logits}\n",
        "\n",
        "        if return_hidden_states:\n",
        "            outputs[\"hidden_states\"] = all_hidden_states\n",
        "\n",
        "        if return_attentions:\n",
        "            outputs[\"attentions\"] = all_attentions\n",
        "\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "RB2qF0e-7j_D"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distil_model = CleanBERT(copy.deepcopy(bert_model.bert.embeddings), config).to(device)\n",
        "for param in distil_model.embeddings.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "71W6qXtYGx0j"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "    \"Hello, how are you?\",\n",
        "    \"Transformers are amazing.\",\n",
        "    \"Distill BERT into a smaller model.\",\n",
        "    \"We reduce dimensions but keep performance.\"\n",
        "]\n",
        "\n",
        "inputs = tokenizer(\n",
        "    sentences,\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    max_length=512,\n",
        "    return_tensors=\"pt\"\n",
        ").to(device)\n",
        "\n",
        "out = distil_model(inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"],\n",
        "                   return_hidden_states=True, return_attentions=True)\n",
        "logits, hidden_states, attentions = out[\"logits\"], out[\"hidden_states\"], out[\"attentions\"]\n",
        "print(logits, len(hidden_states), hidden_states[0].shape, len(attentions), attentions[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12iOpIIhIJVa",
        "outputId": "cb2baeed-c9e7-4e0f-a80c-a062b078266b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0782,  0.1744, -0.6629,  0.1904],\n",
            "        [ 0.1722,  0.2532, -0.2189,  0.3747],\n",
            "        [    nan,     nan,     nan,     nan],\n",
            "        [-0.2258, -0.3420, -0.8435, -0.1836]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>) 7 torch.Size([4, 11, 768]) 6 torch.Size([4, 11, 11])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(distil_model)\n",
        "print(sum(p.numel() for p in distil_model.parameters())) # 69M (0.62 * BertOrigNumParam)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilN8FHv-Hf9b",
        "outputId": "9ed03ea1-1f7b-4eb2-9461-598b3f72a80e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CleanBERT(\n",
            "  (embeddings): BertEmbeddings(\n",
            "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "    (position_embeddings): Embedding(512, 768)\n",
            "    (token_type_embeddings): Embedding(2, 768)\n",
            "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (blocks): ModuleList(\n",
            "    (0-5): 6 x LSTMTransformerBlock(\n",
            "      (lstm): LSTM(768, 384, batch_first=True, bidirectional=True)\n",
            "      (mha): MultiheadAttention(\n",
            "        (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "      )\n",
            "      (ffn): Sequential(\n",
            "        (0): Linear(in_features=768, out_features=1024, bias=True)\n",
            "        (1): GELU(approximate='none')\n",
            "        (2): Linear(in_features=1024, out_features=768, bias=True)\n",
            "      )\n",
            "      (layernorm1): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (layernorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (pooler): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (1): Tanh()\n",
            "  )\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
            ")\n",
            "69341956\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Я беру уже готовые эмбединги. Так что CosDist loss не считаю. Attention loss не использую, у меня разное количество голов.\n",
        "\n",
        "Loss = a * task_loss (CrossEntropy) + b * logits_loss (KLDiv) + c * hidden_states (MSE)"
      ],
      "metadata": {
        "id": "gNp8_NcHNpfH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    outputs = bert_model(\n",
        "        inputs[\"input_ids\"],\n",
        "        attention_mask=inputs[\"attention_mask\"],\n",
        "        output_hidden_states=True,\n",
        "        output_attentions=True\n",
        "    )\n",
        "\n",
        "# Получаем hidden_states: tuple из 13 элементов (embeddings + 12 слоёв)\n",
        "hidden_states = outputs.hidden_states\n",
        "attentions = outputs.attentions\n",
        "hidden_states[12].shape\n",
        "print(len(hidden_states), hidden_states[0].shape)\n",
        "print(len(attentions), attentions[0].shape)"
      ],
      "metadata": {
        "id": "tD5a5G0WKbAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(batch_size=16):\n",
        "    dataset = load_dataset(\"wangrongsheng/ag_news\")\n",
        "\n",
        "    def tokenize(batch):\n",
        "        return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "\n",
        "    encoded_dataset = dataset.map(tokenize, batched=True, batch_size=batch_size)\n",
        "    encoded_dataset = encoded_dataset.remove_columns([\"text\"])\n",
        "    encoded_dataset = encoded_dataset.rename_column(\"label\", \"labels\")\n",
        "    encoded_dataset.set_format(\"torch\")\n",
        "\n",
        "    train_loader = DataLoader(encoded_dataset[\"train\"], batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(encoded_dataset[\"test\"], batch_size=batch_size)\n",
        "\n",
        "    return train_loader, val_loader\n",
        "\n",
        "def kl_div_loss(student_logits, teacher_logits, temperature=2.55):\n",
        "    student_log_probs = F.log_softmax(student_logits / temperature, dim=1)\n",
        "    teacher_probs = F.softmax(teacher_logits / temperature, dim=1)\n",
        "    return F.kl_div(student_log_probs, teacher_probs, reduction='batchmean') * (temperature ** 2)\n",
        "\n",
        "def hidden_state_loss(student_hs, teacher_hs):\n",
        "    return F.mse_loss(student_hs, teacher_hs.detach())\n"
      ],
      "metadata": {
        "id": "V51YfkU0ULrY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_teacher(model, train_loader, val_loader, device, epochs=3, lr=2e-5, save_path=\"bert_teacher_ag_news.pt\"):\n",
        "    optimizer = AdamW(model.parameters(), lr=lr)\n",
        "    total_steps = len(train_loader) * epochs\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        pb = tqdm(train_loader, desc=f\"Epoch {epoch + 1}\")\n",
        "\n",
        "        for i, batch in enumerate(pb):\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            pb.set_postfix(loss=loss.item())\n",
        "\n",
        "            if i == 100:\n",
        "                break\n",
        "\n",
        "        avg_train_loss = total_loss / len(train_loader)\n",
        "        print(f\"\\nEpoch {epoch + 1} | Train Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i, batch in enumerate(val_loader):\n",
        "                input_ids = batch[\"input_ids\"].to(device)\n",
        "                attention_mask = batch[\"attention_mask\"].to(device)\n",
        "                labels = batch[\"labels\"].to(device)\n",
        "\n",
        "                outputs = model(input_ids, attention_mask=attention_mask)\n",
        "                logits = outputs.logits\n",
        "                predictions = torch.argmax(logits, dim=-1)\n",
        "                correct += (predictions == labels).sum().item()\n",
        "                total += labels.size(0)\n",
        "\n",
        "                if i == 100:\n",
        "                    break\n",
        "\n",
        "        accuracy = correct / total\n",
        "        print(f\"Validation Accuracy: {accuracy * 100:.2f}%\\n\")\n",
        "\n",
        "        model.train()\n",
        "\n",
        "    # --- Сохранение модели ---\n",
        "    torch.save(model.state_dict(), save_path)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "QMCgt9b6gKKX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bert_model.load_state_dict(torch.load(\"bert_teacher_ag_news.pt\"))\n",
        "bert_model  = AutoModelForSequenceClassification.from_pretrained(\"fabriceyhc/bert-base-uncased-ag_news\")\n",
        "bert_model.eval()\n",
        "bert_model = bert_model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "f02c652f8ae346ff928e1fb18d7973b0",
            "b26323541a274fefb7b6eb1afafe2a5b",
            "d2e55061d9e648e587de1673170ab369",
            "c9876a815d7347feb8f670657d59a8b9",
            "e665c7f9ba7f4e4ab041ebe1f4aea6f4",
            "2b0d96f52ceb4ead9ff3ed1cd03053de",
            "524bd90cee3844bf812086cdab492a35",
            "215f9dd5b8f7450181bfbd745436cdfa",
            "21288920139741d3abac00a409aa8f24",
            "21bcaf6b9906405185c958be3a62facb",
            "ab7c1c4f3707408c92f5e1c1dda1bbd6",
            "ddd95eeff82b445f840a6d1cb7abe9b0",
            "ca7736ddf2c64b0e9dc3318968640190",
            "55e3780da3b4416ca10753693ba75e72",
            "da25f18fc0d1478cb7a8c827700dc2ef",
            "6bba299848944ccb8250fc5cf861c4fb",
            "82cfa43b197b499e95bf8cf793fd2d37",
            "f0b3e11025a34fd382ba4912195b33e5",
            "9c720d770a6e4f90bb1275c645a98aa7",
            "24bdfb8e6789453bbb4614ad75f630a8",
            "8687fc19733f444c84cbfcef3535ccfe",
            "6944d6d92d304c6fa7458fb8df56f7cc"
          ]
        },
        "collapsed": true,
        "id": "4Gk-Ih4nrtpm",
        "outputId": "9be50c9d-6e17-45f0-a80b-89f8d2d772e3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/919 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f02c652f8ae346ff928e1fb18d7973b0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ddd95eeff82b445f840a6d1cb7abe9b0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project=\"distil_bert_ag_news\", config={\n",
        "    \"a\": 1.55,\n",
        "    \"b\": 0.5,\n",
        "    \"c\": 0.3,\n",
        "    \"batch_size\": 8,\n",
        "    \"epochs\": 5,\n",
        "    \"lr\": 6e-5,\n",
        "    \"temperature\": 2.55\n",
        "})"
      ],
      "metadata": {
        "id": "6rmCES1osH59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "outputId": "6ea47d8c-5415-46a2-a1da-fe08e94e6fc8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>hs_loss</td><td>█▁▃▇▁▁▅</td></tr><tr><td>kl_loss</td><td>█▆▁▅▂▁▂</td></tr><tr><td>step</td><td>▁▂▃▅▆▇█</td></tr><tr><td>task_loss</td><td>▇█▁▄▅▃▃</td></tr><tr><td>train_loss</td><td>█▆▁▅▃▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>hs_loss</td><td>9.67016</td></tr><tr><td>kl_loss</td><td>5.50192</td></tr><tr><td>step</td><td>7</td></tr><tr><td>task_loss</td><td>1.3368</td></tr><tr><td>train_loss</td><td>7.72405</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">faithful-river-11</strong> at: <a href='https://wandb.ai/honkers/distil_bert_ag_news/runs/pej1g7d4' target=\"_blank\">https://wandb.ai/honkers/distil_bert_ag_news/runs/pej1g7d4</a><br> View project at: <a href='https://wandb.ai/honkers/distil_bert_ag_news' target=\"_blank\">https://wandb.ai/honkers/distil_bert_ag_news</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250521_075446-pej1g7d4/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250521_075528-wol4041e</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/honkers/distil_bert_ag_news/runs/wol4041e' target=\"_blank\">volcanic-waterfall-12</a></strong> to <a href='https://wandb.ai/honkers/distil_bert_ag_news' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/honkers/distil_bert_ag_news' target=\"_blank\">https://wandb.ai/honkers/distil_bert_ag_news</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/honkers/distil_bert_ag_news/runs/wol4041e' target=\"_blank\">https://wandb.ai/honkers/distil_bert_ag_news/runs/wol4041e</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/honkers/distil_bert_ag_news/runs/wol4041e?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7c4c7fef6b90>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_distil_model(student_model, teacher_model, tokenizer, device):\n",
        "    train_loader, val_loader = prepare_data(batch_size=wandb.config.batch_size)\n",
        "\n",
        "    optimizer = AdamW(student_model.parameters(), lr=wandb.config.lr)\n",
        "    total_steps = len(train_loader) * wandb.config.epochs\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer, num_warmup_steps=100, num_training_steps=total_steps\n",
        "    )\n",
        "\n",
        "    best_val_acc = 0.0\n",
        "    step = 0\n",
        "\n",
        "    for epoch in range(wandb.config.epochs):\n",
        "        student_model.train()\n",
        "        teacher_model.eval()\n",
        "\n",
        "        total_loss = 0\n",
        "        total_task_loss = 0\n",
        "        total_kl_loss = 0\n",
        "        total_hs_loss = 0\n",
        "\n",
        "        pb = tqdm(train_loader, desc=f\"Epoch {epoch + 1}\")\n",
        "        for batch in pb:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                teacher_outputs = teacher_model(\n",
        "                    input_ids=input_ids,\n",
        "                    attention_mask=attention_mask,\n",
        "                    output_hidden_states=True\n",
        "                )\n",
        "            teacher_logits = teacher_outputs.logits\n",
        "            teacher_hiddens = teacher_outputs.hidden_states\n",
        "\n",
        "            student_outputs = student_model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                return_hidden_states=True\n",
        "            )\n",
        "            student_logits = student_outputs[\"logits\"] if isinstance(student_outputs, dict) else student_outputs\n",
        "            student_hiddens = student_outputs[\"hidden_states\"] if isinstance(student_outputs, dict) else []\n",
        "\n",
        "            task_loss = F.cross_entropy(student_logits, labels)\n",
        "            kl_loss = kl_div_loss(student_logits, teacher_logits, temperature=wandb.config.temperature)\n",
        "\n",
        "            hs_loss = 0\n",
        "            for i, student_hs in enumerate(student_hiddens):\n",
        "                try:\n",
        "                    teacher_hs = teacher_hiddens[i * 2]\n",
        "                    hs_loss += hidden_state_loss(student_hs, teacher_hs)\n",
        "                except IndexError:\n",
        "                    break\n",
        "\n",
        "            total_loss = (\n",
        "                wandb.config.a * task_loss +\n",
        "                wandb.config.b * kl_loss +\n",
        "                wandb.config.c * hs_loss\n",
        "            )\n",
        "\n",
        "            total_loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(student_model.parameters(), 1.0)\n",
        "\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            total_loss_value = total_loss.item()\n",
        "            total_loss += total_loss_value\n",
        "            total_task_loss += task_loss.item()\n",
        "            total_kl_loss += kl_loss.item()\n",
        "            total_hs_loss += hs_loss.item()\n",
        "\n",
        "            pb.set_postfix(loss=total_loss_value, task=task_loss.item(),\n",
        "                           kl=kl_loss.item(), hs=hs_loss.item())\n",
        "\n",
        "            wandb.log({\n",
        "            \"step\": step + 1,\n",
        "            \"train_loss\": total_loss_value,\n",
        "            \"task_loss\": task_loss.item(),\n",
        "            \"kl_loss\": kl_loss.item(),\n",
        "            \"hs_loss\": hs_loss.item()\n",
        "            })\n",
        "\n",
        "            step += 1\n",
        "\n",
        "        student_model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                input_ids = batch[\"input_ids\"].to(device)\n",
        "                attention_mask = batch[\"attention_mask\"].to(device)\n",
        "                labels = batch[\"labels\"].to(device)\n",
        "\n",
        "                outputs = student_model(input_ids, attention_mask=attention_mask)\n",
        "                logits = outputs[\"logits\"] if isinstance(outputs, dict) else outputs\n",
        "                predictions = torch.argmax(logits, dim=1)\n",
        "                correct += (predictions == labels).sum().item()\n",
        "                total += labels.size(0)\n",
        "\n",
        "        val_acc = correct / total\n",
        "\n",
        "        wandb.log({\"epoch\": epoch + 1, \"val_acc\": val_acc})\n",
        "\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            torch.save(student_model.state_dict(), \"best_distilled_model.pt\")\n",
        "\n",
        "        print(f\"Epoch {epoch+1} | Train Loss: {total_loss / len(train_loader):.4f} | Val Acc: {val_acc * 100:.2f}%\\n\")\n",
        "\n",
        "    return student_model"
      ],
      "metadata": {
        "id": "JzQfNBg3y7ax"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_distil_model(distil_model, bert_model, tokenizer, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "eFL2lDOT1Ywn",
        "outputId": "eaaa261a-3574-43f2-cf05-f8e3947bb08f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:   9%|▉         | 1374/15000 [19:36<3:14:25,  1.17it/s, hs=1.84, kl=0.03, loss=0.574, task=0.00476]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-828078ebb88a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_distil_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistil_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-20-8a926adc1014>\u001b[0m in \u001b[0;36mtrain_distil_model\u001b[0;34m(student_model, teacher_model, tokenizer, device)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mteacher_hiddens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mteacher_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             student_outputs = student_model(\n\u001b[0m\u001b[1;32m     38\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-1290e0e68f59>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, return_hidden_states, return_attentions)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mall_attentions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_attention\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreturn_hidden_states\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-1290e0e68f59>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, attention_mask, return_attention)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_attention\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m             result = _VF.lstm(\n\u001b[0m\u001b[1;32m   1125\u001b[0m                 \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m                 \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Возможно лоссы стоит нормализовывать, чтобы их значения были в одном масштабе."
      ],
      "metadata": {
        "id": "8LMrXpy_2ok6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "distil_model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "train_loader, val_loader = prepare_data(batch_size=wandb.config.batch_size)\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(val_loader):\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        outputs = distil_model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs[\"logits\"] if isinstance(outputs, dict) else outputs\n",
        "        predictions = torch.argmax(logits, dim=1)\n",
        "        correct += (predictions == labels).sum().item()\n",
        "        total += labels.size(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2KDN_-thHFM",
        "outputId": "0bec2f0c-1cf6-467a-e602-33a225d7e564"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 950/950 [03:42<00:00,  4.26it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(correct / total)\n",
        "# wandb: https://wandb.ai/honkers/distil_bert_ag_news\n",
        "# У учителя было че-то около 0.93"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UL4lCJ1KhlHH",
        "outputId": "b2b8bd02-b852-4eba-dbb1-7fb1c33cde0e"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8993421052631579\n"
          ]
        }
      ]
    }
  ]
}