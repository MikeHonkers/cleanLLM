{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a2dbd9d499e14bf89a88bb7ffc9cd4d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e41c7f28f7544c1ea1074d6367cb5d8b",
              "IPY_MODEL_e1086be12d9d49209224d841837969f3",
              "IPY_MODEL_f47582aa1a064f6aa8d135542c9f2426"
            ],
            "layout": "IPY_MODEL_1b500295175149fa940915bb72d2aaf4"
          }
        },
        "e41c7f28f7544c1ea1074d6367cb5d8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b288152d44746dca16eab923d10dccf",
            "placeholder": "​",
            "style": "IPY_MODEL_2e79cda91364433c8d063b158d5857c8",
            "value": "Map: 100%"
          }
        },
        "e1086be12d9d49209224d841837969f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_902eaa7f503f4a7ea893f582f7252d37",
            "max": 3000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_080bc38987204a12ac149b84eb9b7660",
            "value": 3000
          }
        },
        "f47582aa1a064f6aa8d135542c9f2426": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc0ce54211f042b0b09479abae0e5e49",
            "placeholder": "​",
            "style": "IPY_MODEL_82e1e708b0ce4e3ebfe4cbdea912db96",
            "value": " 3000/3000 [00:04&lt;00:00, 715.46 examples/s]"
          }
        },
        "1b500295175149fa940915bb72d2aaf4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b288152d44746dca16eab923d10dccf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e79cda91364433c8d063b158d5857c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "902eaa7f503f4a7ea893f582f7252d37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "080bc38987204a12ac149b84eb9b7660": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dc0ce54211f042b0b09479abae0e5e49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82e1e708b0ce4e3ebfe4cbdea912db96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c7444c6b78c48bd82bbf882e68afe29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_51252f8e4ba54c8cba0941ac90d447b2",
              "IPY_MODEL_82e5652cc5d8467799f52c0fc66ac60d",
              "IPY_MODEL_f74024bbbdeb4d53b76a92521a4a9dc4"
            ],
            "layout": "IPY_MODEL_ee280784fd394b9e90123b873806db60"
          }
        },
        "51252f8e4ba54c8cba0941ac90d447b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1a6ad039dcd435dab9b097031782d5d",
            "placeholder": "​",
            "style": "IPY_MODEL_a3c27b7972184f97a5aefa1eb2bde176",
            "value": "Map: 100%"
          }
        },
        "82e5652cc5d8467799f52c0fc66ac60d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acafc4ee81e1435da951bebc1b9f37b3",
            "max": 3000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_719ce04588614b939662658c225ed8e5",
            "value": 3000
          }
        },
        "f74024bbbdeb4d53b76a92521a4a9dc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c7fb2d533474fa58e1f24ccb1203d86",
            "placeholder": "​",
            "style": "IPY_MODEL_71ee25be2d074799bd5d52918edbfd27",
            "value": " 3000/3000 [00:09&lt;00:00, 500.28 examples/s]"
          }
        },
        "ee280784fd394b9e90123b873806db60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1a6ad039dcd435dab9b097031782d5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3c27b7972184f97a5aefa1eb2bde176": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "acafc4ee81e1435da951bebc1b9f37b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "719ce04588614b939662658c225ed8e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1c7fb2d533474fa58e1f24ccb1203d86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71ee25be2d074799bd5d52918edbfd27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U datasets -q"
      ],
      "metadata": {
        "id": "ca9vPWZ6cjBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ALmkUTRI2q5J"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from dataclasses import dataclass\n",
        "import copy\n",
        "import wandb\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from datasets import load_dataset\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from tqdm import tqdm\n",
        "from torch.amp import autocast, GradScaler\n",
        "import numpy as np\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "distil_model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=4).to(device)\n",
        "distil_model.eval()"
      ],
      "metadata": {
        "id": "WQXjmFW37J3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(batch_size=16):\n",
        "    dataset = load_dataset(\"fancyzhx/ag_news\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"Intel/bert-base-uncased-mrpc\")\n",
        "    limit = 6000\n",
        "\n",
        "    def tokenize(batch):\n",
        "        encoded = tokenizer(\n",
        "            text=batch[\"text\"],\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=512,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        encoded = {k: v.long() for k, v in encoded.items()}\n",
        "        return encoded\n",
        "\n",
        "    full_train = dataset[\"train\"]\n",
        "    labels = np.array(full_train[\"label\"])\n",
        "    unique_labels = np.unique(labels)\n",
        "    num_classes = len(unique_labels)\n",
        "    per_class = limit // num_classes\n",
        "\n",
        "    indices = []\n",
        "    for label in unique_labels:\n",
        "        idxs = list(np.where(labels == label)[0])[:per_class]\n",
        "        indices.extend(idxs)\n",
        "\n",
        "    np.random.shuffle(indices)\n",
        "    selected = full_train.select(indices)\n",
        "\n",
        "    split_idx = len(selected) // 2\n",
        "    small_train = selected.select(range(split_idx))\n",
        "    small_val = selected.select(range(split_idx, len(selected)))\n",
        "\n",
        "    encoded_train = small_train.map(tokenize, batched=True, batch_size=batch_size)\n",
        "    encoded_val = small_val.map(tokenize, batched=True, batch_size=batch_size)\n",
        "\n",
        "    encoded_train = encoded_train.remove_columns([\"text\"])\n",
        "    encoded_train = encoded_train.rename_column(\"label\", \"labels\")\n",
        "    encoded_train.set_format(\"torch\")\n",
        "\n",
        "    encoded_val = encoded_val.remove_columns([\"text\"])\n",
        "    encoded_val = encoded_val.rename_column(\"label\", \"labels\")\n",
        "    encoded_val.set_format(\"torch\")\n",
        "\n",
        "    train_loader = DataLoader(encoded_train, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(encoded_val, batch_size=batch_size)\n",
        "\n",
        "    return train_loader, val_loader\n",
        "\n",
        "def kl_div_loss(student_logits, teacher_logits, temperature=2.3):\n",
        "    student_log_probs = F.log_softmax(student_logits / temperature, dim=1)\n",
        "    teacher_probs = F.softmax(teacher_logits / temperature, dim=1)\n",
        "    return F.kl_div(student_log_probs, teacher_probs, reduction='batchmean') * (temperature ** 2)\n",
        "\n",
        "def hidden_state_loss(student_hs, teacher_hs):\n",
        "    return F.mse_loss(student_hs, teacher_hs.detach())\n",
        "\n",
        "def attention_kl_loss(student_attns, teacher_attns, mapping_attn, temperature=2.3):\n",
        "    total_loss = 0.0\n",
        "    num_layers = len(student_attns)\n",
        "\n",
        "    for student_idx in range(num_layers):\n",
        "        student_attn = student_attns[student_idx]  # [B, H, T, T]\n",
        "        teacher_attn = teacher_attns[mapping_attn[student_idx]]  # [B, H, T, T]\n",
        "\n",
        "        B, H, T, _ = student_attn.shape\n",
        "\n",
        "        # Применяем температурное масштабирование\n",
        "        student_attn = student_attn / temperature\n",
        "        teacher_attn = teacher_attn / temperature\n",
        "\n",
        "        # Вычисляем логарифмы вероятностей и вероятности\n",
        "        student_log_probs = F.log_softmax(student_attn, dim=-1)  # [B, H, T, T]\n",
        "        teacher_probs = F.softmax(teacher_attn, dim=-1)  # [B, H, T, T]\n",
        "\n",
        "        # Вычисляем KL-дивергенцию для каждого элемента\n",
        "        kl_per_element = F.kl_div(\n",
        "            student_log_probs,\n",
        "            teacher_probs,\n",
        "            reduction='none'\n",
        "        )  # [B, H, T, T]\n",
        "\n",
        "        # Суммируем по последнему измерению (T)\n",
        "        kl_per_token = kl_per_element.sum(dim=-1)  # [B, H, T]\n",
        "\n",
        "        # Суммируем по всем головам и токенам (но не по батчу!)\n",
        "        kl_per_layer = kl_per_token.sum(dim=(1, 2))  # [B]\n",
        "\n",
        "        # Усредняем по батчу\n",
        "        layer_loss = kl_per_layer.mean()\n",
        "\n",
        "        # Масштабируем обратно температурой\n",
        "        layer_loss = layer_loss * (temperature ** 2)\n",
        "\n",
        "        total_loss += layer_loss\n",
        "\n",
        "    return total_loss / num_layers"
      ],
      "metadata": {
        "id": "V51YfkU0ULrY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_teacher(model, tokenizer, device):\n",
        "    train_loader, val_loader = prepare_data(batch_size=16)\n",
        "\n",
        "    optimizer = AdamW(model.parameters(), lr=6e-5)\n",
        "    total_steps = len(train_loader) * 2\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer, num_warmup_steps=100, num_training_steps=total_steps\n",
        "    )\n",
        "\n",
        "    best_val_acc = 0.0\n",
        "    step = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(2):\n",
        "        epoch_task_loss = 0\n",
        "\n",
        "        pb = tqdm(train_loader, desc=f\"Epoch {epoch + 1}\")\n",
        "        for batch in pb:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            student_outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask\n",
        "            )\n",
        "            student_logits = student_outputs.logits\n",
        "\n",
        "            task_loss = F.cross_entropy(student_logits, labels)\n",
        "\n",
        "            total_loss = task_loss\n",
        "\n",
        "            total_loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(val_loader):\n",
        "                input_ids = batch[\"input_ids\"].to(device)\n",
        "                attention_mask = batch[\"attention_mask\"].to(device)\n",
        "                labels = batch[\"labels\"].to(device)\n",
        "\n",
        "                outputs = model(input_ids, attention_mask=attention_mask)\n",
        "                preds = torch.argmax(outputs.logits, dim=1)\n",
        "                correct += (preds == labels).sum().item()\n",
        "                total += labels.size(0)\n",
        "        print(\"\\n\", correct / total)\n",
        "\n",
        "        step += 1\n",
        "\n",
        "train_teacher(distil_model, tokenizer, 'cuda')\n",
        "\n",
        "# 0.81"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226,
          "referenced_widgets": [
            "a2dbd9d499e14bf89a88bb7ffc9cd4d8",
            "e41c7f28f7544c1ea1074d6367cb5d8b",
            "e1086be12d9d49209224d841837969f3",
            "f47582aa1a064f6aa8d135542c9f2426",
            "1b500295175149fa940915bb72d2aaf4",
            "6b288152d44746dca16eab923d10dccf",
            "2e79cda91364433c8d063b158d5857c8",
            "902eaa7f503f4a7ea893f582f7252d37",
            "080bc38987204a12ac149b84eb9b7660",
            "dc0ce54211f042b0b09479abae0e5e49",
            "82e1e708b0ce4e3ebfe4cbdea912db96",
            "5c7444c6b78c48bd82bbf882e68afe29",
            "51252f8e4ba54c8cba0941ac90d447b2",
            "82e5652cc5d8467799f52c0fc66ac60d",
            "f74024bbbdeb4d53b76a92521a4a9dc4",
            "ee280784fd394b9e90123b873806db60",
            "d1a6ad039dcd435dab9b097031782d5d",
            "a3c27b7972184f97a5aefa1eb2bde176",
            "acafc4ee81e1435da951bebc1b9f37b3",
            "719ce04588614b939662658c225ed8e5",
            "1c7fb2d533474fa58e1f24ccb1203d86",
            "71ee25be2d074799bd5d52918edbfd27"
          ]
        },
        "id": "XmNp0lJn_FvS",
        "outputId": "569f2f39-544e-406e-de08-967c43c8ac48"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a2dbd9d499e14bf89a88bb7ffc9cd4d8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5c7444c6b78c48bd82bbf882e68afe29"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 188/188 [04:27<00:00,  1.42s/it]\n",
            "100%|██████████| 188/188 [01:28<00:00,  2.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " 0.884\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 188/188 [04:19<00:00,  1.38s/it]\n",
            "100%|██████████| 188/188 [01:28<00:00,  2.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " 0.9156666666666666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model = copy.deepcopy(distil_model)"
      ],
      "metadata": {
        "id": "4WUfxXRM62hT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class DistBERTConfig:\n",
        "    bert_hidden_size: int = 768\n",
        "    num_blocks: int = 4\n",
        "    num_heads: int = 12\n",
        "    intermediate_size: int = 1024\n",
        "    dropout: float = 0.1\n",
        "\n",
        "config = DistBERTConfig()"
      ],
      "metadata": {
        "id": "kKb7i7F56w9j"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.mha = nn.MultiheadAttention(\n",
        "            embed_dim=config.bert_hidden_size,\n",
        "            num_heads=config.num_heads,\n",
        "            dropout=config.dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        self.ffn = nn.Sequential(\n",
        "            nn.Linear(config.bert_hidden_size, config.intermediate_size),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(config.intermediate_size, config.bert_hidden_size)\n",
        "        )\n",
        "\n",
        "        self.layernorm1 = nn.LayerNorm(config.bert_hidden_size, eps=1e-12)\n",
        "        self.layernorm2 = nn.LayerNorm(config.bert_hidden_size, eps=1e-12)\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "    def forward(self, x, attention_mask=None, return_attention=False):\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            attention_mask = ~attention_mask.bool()\n",
        "        else:\n",
        "            attention_mask = None\n",
        "\n",
        "        mha_out, attn_weights = self.mha(\n",
        "            query=x,\n",
        "            key=x,\n",
        "            value=x,\n",
        "            key_padding_mask=attention_mask,\n",
        "            need_weights=return_attention,\n",
        "            average_attn_weights=False\n",
        "        )\n",
        "\n",
        "        residual = x + self.dropout(mha_out)\n",
        "        x = self.layernorm1(residual)\n",
        "\n",
        "        ffn_out = self.ffn(x)\n",
        "        residual = x + self.dropout(ffn_out)\n",
        "        output = self.layernorm2(residual)\n",
        "\n",
        "        if return_attention:\n",
        "            return output, attn_weights\n",
        "        else:\n",
        "            return output\n",
        "\n",
        "class CleanBERT(nn.Module):\n",
        "    def __init__(self, embedding_layer, config, num_labels=4):\n",
        "        super().__init__()\n",
        "        self.embeddings = embedding_layer\n",
        "\n",
        "        self.blocks = nn.ModuleList([\n",
        "            TransformerBlock(config) for _ in range(config.num_blocks)\n",
        "        ])\n",
        "\n",
        "        self.pooler = nn.Sequential(\n",
        "            nn.Linear(config.bert_hidden_size, config.bert_hidden_size),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "        self.classifier = nn.Linear(config.bert_hidden_size, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None,\n",
        "                return_hidden_states=False, return_attentions=False):\n",
        "        x = self.embeddings(input_ids)\n",
        "\n",
        "        all_hidden_states = []\n",
        "        all_attentions = []\n",
        "\n",
        "        if return_hidden_states:\n",
        "            all_hidden_states.append(x)\n",
        "\n",
        "        for block in self.blocks:\n",
        "            if return_attentions:\n",
        "                x, attn = block(x, attention_mask=attention_mask, return_attention=True)\n",
        "                all_attentions.append(attn)\n",
        "            else:\n",
        "                x = block(x, attention_mask=attention_mask, return_attention=False)\n",
        "\n",
        "            if return_hidden_states:\n",
        "                all_hidden_states.append(x)\n",
        "\n",
        "        cls_output = x[:, 0]\n",
        "\n",
        "        pooled = self.pooler(cls_output)\n",
        "        pooled = self.dropout(pooled)\n",
        "        logits = self.classifier(pooled)\n",
        "\n",
        "        outputs = {\"logits\": logits}\n",
        "\n",
        "        if return_hidden_states:\n",
        "            outputs[\"hidden_states\"] = all_hidden_states\n",
        "\n",
        "        if return_attentions:\n",
        "            outputs[\"attentions\"] = all_attentions\n",
        "\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "_4aMGlDg6xab"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distil_model = CleanBERT(copy.deepcopy(bert_model.bert.embeddings), config).to(device)\n",
        "for param in distil_model.embeddings.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "xSw2VlYS6zaT"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project=\"bert_mrpc_restricted-losses\", config={\n",
        "    \"a\": 0,\n",
        "    \"b\": 1,\n",
        "    \"c\": 1,\n",
        "    \"d\": 0,\n",
        "    \"batch_size\": 8,\n",
        "    \"epochs\": 13,\n",
        "    \"lr\": 6e-5,\n",
        "    \"temperature\": 1.5\n",
        "})"
      ],
      "metadata": {
        "id": "6rmCES1osH59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_distil_model(student_model, teacher_model, tokenizer, device):\n",
        "    train_loader, val_loader = prepare_data(batch_size=wandb.config.batch_size)\n",
        "\n",
        "    optimizer = AdamW(student_model.parameters(), lr=wandb.config.lr)\n",
        "    total_steps = len(train_loader) * wandb.config.epochs\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer, num_warmup_steps=100, num_training_steps=total_steps\n",
        "    )\n",
        "\n",
        "    best_val_acc = 0.0\n",
        "    step = 0\n",
        "\n",
        "    scaler = GradScaler('cuda')\n",
        "\n",
        "    mapping_attn = [2, 5, 8, 11]\n",
        "    mapping_mse_full = [0, 3, 6, 9, 12]\n",
        "\n",
        "    student_model.train()\n",
        "    teacher_model.eval()\n",
        "\n",
        "    for epoch in range(wandb.config.epochs):\n",
        "        total_loss = 0\n",
        "        total_task_loss = 0\n",
        "        total_kl_loss = 0\n",
        "        total_hs_loss = 0\n",
        "        total_attn_loss = 0\n",
        "\n",
        "        pb = tqdm(train_loader, desc=f\"Epoch {epoch + 1}\")\n",
        "        for batch in pb:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                teacher_outputs = teacher_model(\n",
        "                    input_ids=input_ids,\n",
        "                    attention_mask=attention_mask,\n",
        "                    output_hidden_states=True,\n",
        "                    output_attentions=True\n",
        "                )\n",
        "            teacher_logits = teacher_outputs.logits\n",
        "            teacher_hiddens = teacher_outputs.hidden_states\n",
        "            teacher_attns = teacher_outputs.attentions\n",
        "\n",
        "            with autocast('cuda', dtype=torch.float16):\n",
        "                student_outputs = student_model(\n",
        "                    input_ids=input_ids,\n",
        "                    attention_mask=attention_mask,\n",
        "                    return_hidden_states=True,\n",
        "                    return_attentions=True\n",
        "                )\n",
        "                student_logits = student_outputs[\"logits\"]\n",
        "                student_hiddens = student_outputs[\"hidden_states\"]\n",
        "                student_attns = student_outputs[\"attentions\"]\n",
        "\n",
        "                task_loss = F.cross_entropy(student_logits, labels)\n",
        "                kl_loss = kl_div_loss(student_logits, teacher_logits, temperature=wandb.config.temperature)\n",
        "\n",
        "                hs_loss = 0\n",
        "                for i, student_hs in enumerate(student_hiddens):\n",
        "                    teacher_hs = teacher_hiddens[mapping_mse_full[i]]\n",
        "                    hs_loss += hidden_state_loss(student_hs, teacher_hs)\n",
        "\n",
        "                attn_loss = attention_kl_loss(\n",
        "                    student_attns,\n",
        "                    teacher_attns,\n",
        "                    mapping_attn,\n",
        "                    temperature=wandb.config.temperature\n",
        "                )\n",
        "\n",
        "                total_loss = (\n",
        "                    wandb.config.a * task_loss +\n",
        "                    wandb.config.b * kl_loss +\n",
        "                    wandb.config.c * hs_loss +\n",
        "                    wandb.config.d * attn_loss\n",
        "                )\n",
        "\n",
        "            scaler.scale(total_loss).backward()\n",
        "            torch.nn.utils.clip_grad_norm_(student_model.parameters(), 1.0)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            total_loss_value = total_loss.item()\n",
        "            total_task_loss += task_loss.item()\n",
        "            total_kl_loss += kl_loss.item()\n",
        "            total_hs_loss += hs_loss.item()\n",
        "            total_attn_loss += attn_loss.item()\n",
        "\n",
        "            pb.set_postfix(\n",
        "                loss=total_loss_value,\n",
        "                task=task_loss.item(),\n",
        "                kl=kl_loss.item(),\n",
        "                hs=hs_loss.item(),\n",
        "                attn=attn_loss.item()\n",
        "            )\n",
        "\n",
        "            wandb.log({\n",
        "                \"step\": step + 1,\n",
        "                \"train_loss\": total_loss_value,\n",
        "                \"task_loss\": task_loss.item(),\n",
        "                \"kl_loss\": kl_loss.item(),\n",
        "                \"hs_loss\": hs_loss.item(),\n",
        "                \"attn_loss\": attn_loss.item()\n",
        "            })\n",
        "\n",
        "            step += 1\n",
        "\n",
        "        student_model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                input_ids = batch[\"input_ids\"].to(device)\n",
        "                attention_mask = batch[\"attention_mask\"].to(device)\n",
        "                labels = batch[\"labels\"].to(device)\n",
        "\n",
        "                outputs = student_model(input_ids, attention_mask=attention_mask)\n",
        "                logits = outputs[\"logits\"] if isinstance(outputs, dict) else outputs\n",
        "                predictions = torch.argmax(logits, dim=1)\n",
        "                correct += (predictions == labels).sum().item()\n",
        "                total += labels.size(0)\n",
        "\n",
        "        val_acc = correct / total\n",
        "        wandb.log({\"epoch\": epoch + 1, \"val_acc\": val_acc})\n",
        "\n",
        "        print(f\"Epoch {epoch+1} | Val Acc: {val_acc * 100:.2f}%\\n\")\n",
        "\n",
        "    return student_model"
      ],
      "metadata": {
        "id": "JzQfNBg3y7ax"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_distil_model(distil_model, bert_model, tokenizer, device)"
      ],
      "metadata": {
        "id": "eFL2lDOT1Ywn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}